configfile: "config/config.yaml"

rule all:
    input:
        "results/trees_all.tre"

# Creates and populates a SQLite database with filtered sequence records.
# Uses BOLD dump TSV as defined in config file
rule create_database:
  input: config["file_names"]["bold_tsv"]
  output: 'results/databases/create_database.ok'
  params:
    db="results/databases/BOLD_{}_barcodes.db".format(config["marker"]),
    marker=config["marker"],
    minlength=config["minlength"],
    log_level=config['log_level']
  conda: "envs/create_database.yml"
  log: "logs/create_database.log"
  shell:
    """
    python workflow/scripts/bold_data_dump.py \
      -v {params.log_level} \
      -l {params.minlength} \
      -d {params.db} \
      -t {input} \
      -m {params.marker} 2> {log}
    touch {output}
    """

# Enriches the database with mappings to OpenToL. Because this operates on
# the same database file, the output is a 0-byte file `map_opentol.ok` to
# indicate that the task was run.
rule map_opentol:
  input: rules.create_database.output
  output: 'results/databases/map_opentol.ok'
  params:
    db="results/databases/BOLD_{}_barcodes.db".format(config["marker"]),
    marker=config['marker'],
    log_level=config['log_level']
  conda: "envs/map_opentol.yml"
  log: "logs/map_opentol.log"
  shell:
      """
      python workflow/scripts/map_opentol.py \
        -d {params.db} \
        -m {params.marker} \
        -v {params.log_level} \
        -o {output} 2> {log}
      """

# Creates and populates the OpenToL SQLite database. Uses the location of
# the OpenToL tree as per the config file. Merges the resulting database
# with the BOLD database (which gains a table `node`). SQLite can, at time
# of writing, not apply foreign key constraints retroactively. This is a
# shame because taxon.opentol_id implicitly references node.id.
rule megatree_loader:
    input:
        tree = config["file_names"]["open_tre"],
        mapping_ok = rules.map_opentol.output
    output: 'results/databases/megatree_loader.ok'
    conda: "envs/megatree_loader.yml"
    log: "logs/megatree_loader.log"
    params:
        db="results/databases/BOLD_{}_barcodes.db".format(config["marker"]),
        tempdb = temp("results/databases/opentree_nodes.db"),
        tempsql = temp("results/databases/node.sql")
    shell:
        """
        megatree-loader -i {input.tree} -d {params.tempdb} -v 2> {log}
        sqlite3 {params.tempdb} ".dump node" > {params.tempsql} 2>> {log}
        sqlite3 {params.db} < {params.tempsql} 2>> {log}
        touch {output} 2>> {log}
        rm {params.tempsql} {params.tempdb}
        """


scattergather:
  split = config["nfamilies"]

# Exports unaligned BIN sequences aggregated at family level.
rule family_fasta:
    input: rules.map_opentol.output
    output: scatter.split("results/fasta/family/{scatteritem}/unaligned.fa")
    params:
      log_level=config['log_level'],
      fasta_dir=config["file_names"]["fasta_dir"],
      filter_level=config["fasta_filter"]["filter_level"],
      filter_name=config["fasta_filter"]["filter_name"],
      db="results/databases/BOLD_{}_barcodes.db".format(config["marker"]),
      chunks=config["nfamilies"],
    conda: "envs/family_fasta.yml"
    log: "logs/family_fasta.log"
    shell:
        """
        python workflow/scripts/family_fasta.py \
            -d {params.db} \
            -f {params.fasta_dir} \
            -l {params.filter_level} \
            -n {params.filter_name} \
            -c {params.chunks} \
            -v {params.log_level} 2> {log}
        """

# Exports OpenToL newick file for each unaligned BIN sequence file
rule family_constraint:
    input: "results/fasta/family/{scatteritem}/unaligned.fa"
    output: "results/fasta/family/{scatteritem}/unaligned.tre"
    params:
        temp=config["file_names"]["fasta_dir"] + "/{scatteritem}/unaligned.txt",
        db="results/databases/BOLD_{}_barcodes.db".format(config["marker"])
    conda: "envs/family_constraint.yml"
    log: "logs/family_constraint-{scatteritem}.log"
    shell:
        """
        grep '>' {input} | cut -f2 -d'|' | sort | uniq > {params.temp} 2> {log}
        megatree-pruner -i {params.temp} -d {params.db} -v > {output} 2>> {log}
        """

# Aligns sequences with HMM.
rule msa_hmm:
    input: "results/fasta/family/{scatteritem}/unaligned.fa"
    output: "results/fasta/family/{scatteritem}/aligned.phy"
    params:
        log_level=config['log_level'],
        hmm_file=config['file_names']['hmm']
    conda: "envs/msa_hmm.yml"
    log: "logs/msa_hmm-{scatteritem}.log"
    shell:
        """
        python workflow/scripts/msa_hmm.py \
            -i {input} \
            -o {output} \
            -m {params.hmm_file} \
            -v {params.log_level} 2> {log}             
        """

rule prep_raxml:
    input:
        alignment="results/fasta/family/{scatteritem}/aligned.phy",
        tree="results/fasta/family/{scatteritem}/unaligned.tre"
    output:
        alignment="results/fasta/family/{scatteritem}/raxml-ready.fa",
        tree="results/fasta/family/{scatteritem}/raxml-ready.tre"
    params:
        db="results/databases/BOLD_{}_barcodes.db".format(config["marker"]),
        log_level=config['log_level'],
    conda: "envs/prep_raxml.yml"
    log: "logs/prep_raxml-{scatteritem}.log"
    shell:
        """
        python workflow/scripts/prep_raxml.py \
            -t {input.tree} \
            -o {output.tree} \
            -a {input.alignment} \
            -f {output.alignment} \
            -v {params.log_level} \
            -d {params.db} 2> {log}            
        """


# gathers the results
rule final_rule:
    input:
        fastas=gather.split("results/fasta/family/{scatteritem}/raxml-ready.fa"),
        trees=gather.split("results/fasta/family/{scatteritem}/raxml-ready.tre")
    output:
        fasta="results/aligned_all.fa",
        trees="results/trees_all.tre"
    shell:
        """
        cat {input.fastas} > {output.fasta}
        cat {input.trees} > {output.trees}
        """
